{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "262c5728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process for Training:\n",
    "# 1. L̶o̶a̶d̶ ̶i̶n̶ ̶i̶m̶a̶g̶e̶ ̶a̶n̶d̶ ̶m̶a̶k̶e̶ ̶i̶t̶ ̶5̶1̶2̶x̶5̶1̶2̶  I will do preprocessing before to make file sizes smaller for training.\n",
    "# 2. Apply various pertubations/distortions on image\n",
    "# 3. Clone image, and create the generator copy (this is what is fed to generator)\n",
    "\n",
    "\n",
    "# The functions defined below are configured such that you input a single image and it will return\n",
    "# what you need to feed to the generator and what you need to feed to the discriminator\n",
    "\n",
    "# I start by loading randomly sized images and scale them all to 512x512x3\n",
    "# The generator image will be cut such that it hides 56 pixels from each side\n",
    "\n",
    "# In this script, I have two methods for loading in files. The first is through randomly sized images in a directory saved\n",
    "# as .jpgs. The second is through a TFrecord on pre-processed data to be exactly 512x512x3. The second method is a smaller\n",
    "# file size so it is easier to train on and can be cached / stored on memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9acbadc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def parse_tfrecord_fn(example_proto):\n",
    "    feature_description = {\n",
    "        'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'width': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    image = tf.io.decode_jpeg(example['image_raw'], channels=3)\n",
    "    return image\n",
    "\n",
    "# For loading the TfRecord\n",
    "# I should vectorize my mappings (random jitter / generator image) to work on batches\n",
    "# \n",
    "def load_tfrecord(tfrecord_file, batch_size, buffer=56):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    dataset = dataset.map(parse_tfrecord_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.cache() # Store the loaded data into memory\n",
    "    dataset = dataset.map(random_jitter, num_parallel_calls=tf.data.AUTOTUNE) # Apply tranformations every epoch\n",
    "    dataset = dataset.map(lambda x: (generator_image(x, buffer), x)) \n",
    "    dataset = dataset.batch(batch_size) # Batch every epoch, dont store batches in memory\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE) # prefetch to speed up subsequent computations\n",
    "    return dataset\n",
    "\n",
    "def resize(input_image, height, width):\n",
    "    return tf.image.resize(input_image, [height, width], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "def random_crop(input_image, height, width):\n",
    "    return tf.image.random_crop(input_image, size=[height, width, 3])\n",
    "\n",
    "# Normalizing the images to [-1, 1]\n",
    "def normalize(input_image):\n",
    "    input_image = tf.cast(input_image, dtype=tf.float32)\n",
    "    input_image = (input_image / 127.5) - 1 # want a mean near 0\n",
    "    return input_image\n",
    "\n",
    "def denormalize(input_image):\n",
    "    input_image = (input_image + 1) * 127.5\n",
    "    input_image = tf.cast(input_image, dtype=tf.int64)\n",
    "    return input_image\n",
    "\n",
    "def generator_image(input_image, buffer=56):\n",
    "    height = len(input_image[0])\n",
    "    width = len(input_image[1])\n",
    "    paddings = tf.constant([[buffer, buffer], [buffer, buffer], [0, 0]])\n",
    "    generator_image = tf.pad(input_image[buffer:(height-buffer), buffer:(width-buffer), :], \n",
    "                             paddings, constant_values=0) # constant values should probably cycle between -1 and 1\n",
    "    return generator_image\n",
    "\n",
    "@tf.function()\n",
    "def random_jitter(input_image):\n",
    "    # Resizing to 542x542\n",
    "    input_image = resize(input_image, 542, 542)\n",
    "    # Random cropping back to 512x512\n",
    "    input_image= random_crop(input_image, 512, 512)\n",
    "    # Random mirroring\n",
    "    input_image = tf.image.random_flip_left_right(input_image)\n",
    "    # Normalizing image\n",
    "    input_image = normalize(input_image)\n",
    "    return input_image\n",
    "\n",
    "# Loading a single jpg\n",
    "def train_image_load(image_file, buffer=56):\n",
    "    input_image = load(image_file)\n",
    "    # Apply various pertubations/distortions on image\n",
    "    input_image = random_jitter(input_image)\n",
    "    # Clone image, and create the generator copy\n",
    "    gen_image = generator_image(input_image, buffer)\n",
    "    return gen_image, input_image\n",
    "\n",
    "# Loading a single jpg.\n",
    "def load(image_file):\n",
    "    image = tf.io.read_file(image_file)\n",
    "    image = tf.io.decode_jpeg(image, channels = 3)\n",
    "    return image\n",
    "\n",
    "# Note: path must contain final \\\\\n",
    "def load_IMGS(path, batch_size):\n",
    "    dataset = tf.data.Dataset.list_files(str(path+ '*.jpg'))\n",
    "    dataset = dataset.map(train_image_load,\n",
    "                                  num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ec68772",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_path = \"C:\\\\Users\\\\Ilyas\\\\Desktop\\\\images.tfrecord\"\n",
    "images_path = \"C:\\\\Users\\\\Ilyas\\\\Desktop\\\\Hot-o-bot\\\\New folder\\\\\"\n",
    "BUFFER_SIZE = 400\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "dataset1 = load_tfrecord(tfrecord_path, BATCH_SIZE)\n",
    "dataset2 = load_IMGS(images_path, BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6fad3c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "for i in dataset1.take(1):\n",
    "    print(i[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b21b66c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
